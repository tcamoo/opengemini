// Gemini 3 Pro / OpenAI å…¼å®¹æ¥å£ - Cloudflare Worker å®Œæ•´ç‰ˆ
// å·²ç§»é™¤ node:buffer æŠ¥é”™ï¼Œå¢åŠ é¦–é¡µçŠ¶æ€æ˜¾ç¤º

export default {
  async fetch (request) {
    // 1. å¤„ç† OPTIONS é¢„æ£€è¯·æ±‚ (è§£å†³è·¨åŸŸé—®é¢˜)
    if (request.method === "OPTIONS") {
      return handleOPTIONS();
    }

    const url = new URL(request.url);
    const { pathname } = url;

    // 2. é¦–é¡µçŠ¶æ€æ£€æŸ¥ (è§£å†³æ‰“å¼€æ˜¯ 404 çš„é—®é¢˜)
    if (pathname === "/" || pathname === "/health") {
      return new Response(JSON.stringify({
        status: "Success",
        message: "Gemini 3 Pro Proxy is Active! ğŸš€",
        guide: "Please set Base URL to: " + url.origin + "/v1",
        model_support: "gemini-3-pro-preview, gemini-2.0-flash-exp, gemini-1.5-pro"
      }, null, 2), {
        status: 200,
        headers: { "Content-Type": "application/json", "Access-Control-Allow-Origin": "*" }
      });
    }

    const errHandler = (err) => {
      console.error(err);
      return new Response(JSON.stringify({ error: { message: err.message, type: "internal_error" } }), {
        status: 500,
        headers: { "Content-Type": "application/json", "Access-Control-Allow-Origin": "*" }
      });
    };

    try {
      const auth = request.headers.get("Authorization");
      const apiKey = auth?.split(" ")[1];
      
      // è·¯ç”±åˆ†å‘
      switch (true) {
        case pathname.endsWith("/chat/completions"):
          if (request.method !== "POST") throw new Error("Method Not Allowed");
          return handleCompletions(await request.json(), apiKey).catch(errHandler);
          
        case pathname.endsWith("/embeddings"):
          if (request.method !== "POST") throw new Error("Method Not Allowed");
          return handleEmbeddings(await request.json(), apiKey).catch(errHandler);
          
        case pathname.endsWith("/models"):
          return handleModels(apiKey).catch(errHandler);
          
        default:
          return new Response("404 Not Found (Check your endpoint path, usually /v1/chat/completions)", { status: 404 });
      }
    } catch (err) {
      return errHandler(err);
    }
  }
};

// === æ ¸å¿ƒé€»è¾‘éƒ¨åˆ† ===

const BASE_URL = "https://generativelanguage.googleapis.com";
const API_VERSION = "v1beta"; // Gemini 3 Pro é€šå¸¸åœ¨ beta ç‰ˆæœ¬å¯ç”¨

// é»˜è®¤æ¨¡å‹è®¾ç½®ï¼šå¦‚æœå®¢æˆ·ç«¯ä¸ä¼ æ¨¡å‹ï¼Œé»˜è®¤ç”¨è¿™ä¸ª
const DEFAULT_MODEL = "gemini-3-pro-preview"; 

// è¾…åŠ©ï¼šå¤„ç† CORS
const fixCors = (response) => {
  const newHeaders = new Headers(response.headers);
  newHeaders.set("Access-Control-Allow-Origin", "*");
  return new Response(response.body, {
    status: response.status,
    statusText: response.statusText,
    headers: newHeaders
  });
};

const handleOPTIONS = async () => {
  return new Response(null, {
    headers: {
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization",
    }
  });
};

async function handleModels (apiKey) {
  // è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨åˆ—å‡ºæ”¯æŒçš„æ¨¡å‹ï¼Œæ–¹ä¾¿å®¢æˆ·ç«¯è¯†åˆ«
  const models = [
    { id: "gemini-3-pro-preview", object: "model", created: 1731974400, owned_by: "google" },
    { id: "gemini-2.0-flash-exp", object: "model", created: 1731974400, owned_by: "google" },
    { id: "gemini-1.5-pro", object: "model", created: 1715644800, owned_by: "google" },
    { id: "gemini-1.5-flash", object: "model", created: 1715644800, owned_by: "google" }
  ];
  return new Response(JSON.stringify({ object: "list", data: models }), {
    headers: { "Content-Type": "application/json", "Access-Control-Allow-Origin": "*" }
  });
}

async function handleCompletions (req, apiKey) {
  let model = req.model || DEFAULT_MODEL;
  
  // æ™ºèƒ½æ¨¡å‹åç§°æ˜ å°„ (é˜²æ­¢å®¢æˆ·ç«¯ä¹±ä¼ )
  if (model.includes("gpt")) model = DEFAULT_MODEL; 
  if (model === "gemini-3-pro") model = "gemini-3-pro-preview"; // ä¿®æ­£åç§°
  
  // å¤„ç†æ¨¡å‹å‰ç¼€
  const cleanModel = model.replace(/^models\//, "").replace(/^gemini-/, "gemini-");
  const finalModel = cleanModel.startsWith("gemini-") ? cleanModel : "gemini-" + cleanModel;

  const url = `${BASE_URL}/${API_VERSION}/models/${finalModel}:${req.stream ? "streamGenerateContent" : "generateContent"}?alt=sse&key=${apiKey}`;

  const body = await transformRequest(req);

  const response = await fetch(url, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(body),
  });

  if (!response.ok) {
    return fixCors(response);
  }

  // æµå¼å¤„ç†æˆ–æ™®é€šè¿”å›
  if (req.stream) {
    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    const reader = response.body.getReader();
    const encoder = new TextEncoder();
    const decoder = new TextDecoder();

    // å¼‚æ­¥å¤„ç†æµ
    (async () => {
      let buffer = "";
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          if (buffer) processChunk(buffer, writer, encoder, model);
          await writer.write(encoder.encode("data: [DONE]\n\n"));
          await writer.close();
          break;
        }
        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split("\n");
        buffer = lines.pop(); 
        for (const line of lines) {
           processChunk(line, writer, encoder, model);
        }
      }
    })();

    return new Response(readable, {
      headers: { "Content-Type": "text/event-stream", "Access-Control-Allow-Origin": "*" }
    });
  } else {
    // éæµå¼
    const json = await response.json();
    const openaiResponse = transformResponse(json, model);
    return new Response(JSON.stringify(openaiResponse), {
      headers: { "Content-Type": "application/json", "Access-Control-Allow-Origin": "*" }
    });
  }
}

// === æ ¸å¿ƒæ•°æ®è½¬æ¢å·¥å…· (OpenAI <-> Gemini) ===

async function transformRequest(req) {
  const contents = [];
  let systemInstruction = undefined;

  for (const msg of req.messages) {
    if (msg.role === "system") {
      systemInstruction = { parts: [{ text: msg.content }] };
    } else {
      const parts = [];
      if (Array.isArray(msg.content)) {
        for (const part of msg.content) {
          if (part.type === "text") parts.push({ text: part.text });
          if (part.type === "image_url") {
            const imgData = await fetchImageAsBase64(part.image_url.url);
            parts.push({ inlineData: { mimeType: "image/jpeg", data: imgData } });
          }
        }
      } else {
        parts.push({ text: msg.content });
      }
      contents.push({ role: msg.role === "assistant" ? "model" : "user", parts });
    }
  }

  return {
    contents,
    systemInstruction,
    generationConfig: {
      temperature: req.temperature,
      maxOutputTokens: req.max_tokens,
    }
  };
}

// è¾…åŠ©ï¼šä¸‹è½½å›¾ç‰‡å¹¶è½¬Base64 (åŸç”Ÿ fetchï¼Œä¸ä¾èµ– node:buffer)
async function fetchImageAsBase64(url) {
  const resp = await fetch(url);
  const arrayBuffer = await resp.arrayBuffer();
  let binary = '';
  const bytes = new Uint8Array(arrayBuffer);
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

// å¤„ç†æµå¼ Chunk
function processChunk(line, writer, encoder, model) {
  if (!line.startsWith("data: ")) return;
  try {
    const data = JSON.parse(line.slice(6));
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
    if (text) {
      const chunk = {
        id: "chatcmpl-" + Date.now(),
        object: "chat.completion.chunk",
        created: Math.floor(Date.now() / 1000),
        model: model,
        choices: [{ index: 0, delta: { content: text }, finish_reason: null }]
      };
      writer.write(encoder.encode("data: " + JSON.stringify(chunk) + "\n\n"));
    }
  } catch (e) { }
}

// å¤„ç†æ™®é€šå“åº”
function transformResponse(data, model) {
  const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
  return {
    id: "chatcmpl-" + Date.now(),
    object: "chat.completion",
    created: Math.floor(Date.now() / 1000),
    model: model,
    choices: [{ index: 0, message: { role: "assistant", content: text }, finish_reason: "stop" }],
    usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 } // Gemini API è¿”å›çš„ usage æ ¼å¼ä¸åŒï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
  };
}

async function handleEmbeddings(req) {
   return new Response(JSON.stringify({ error: "Embeddings not supported in this simplified version" }), { status: 400 });
}
